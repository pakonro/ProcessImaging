{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pakonro/ProcessImaging/blob/main/Kopie_von_ipi_data_analysis_2023_session1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "import cv2, h5py, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import skimage.morphology as morphology\n",
        "import skimage.measure as measure\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import shutil, os, requests\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Mb3VbTm5NdJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C46VT4kNWbn"
      },
      "outputs": [],
      "source": [
        "# load custom functions\n",
        "def write_to_h5(h5file, data):\n",
        "    hf = h5py.File(str(h5file), 'w')\n",
        "    hf.create_dataset('data', data=data)\n",
        "    hf.close()\n",
        "\n",
        "def read_from_h5(h5file):\n",
        "    hf = h5py.File(h5file, 'r')\n",
        "    return np.array(hf.get(\"data\"))\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        total_length = int(r.headers.get(\"Content-Length\"))\n",
        "        with tqdm.wrapattr(r.raw, \"read\", total=total_length, desc=file_name)as raw:\n",
        "            with open(file_name, 'wb')as output:\n",
        "                shutil.copyfileobj(raw, output)\n",
        "\n",
        "data_analysis_results = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 | Download Data"
      ],
      "metadata": {
        "id": "Gzp5BXNSkh62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download data (h5)\n",
        "# ------------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------------\n",
        "data_id = 0  # <- change this according to the list below and download the file\n",
        "             #    you want to download by executing this cell\n",
        "# ------------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "urls_h5 = [\n",
        "    ('g1-data-h5', 'https://cloud.tuhh.de/index.php/s/97rR8gW6XZToT3S/download'),  # data_id = 0\n",
        "    ('g2-data-h5', 'https://cloud.tuhh.de/index.php/s/NegW8RaBdAqa7NW/download'),  # data_id = 1\n",
        "    ('g3-data-h5', 'https://cloud.tuhh.de/index.php/s/L9dLAgiTe6LGR3k/download'),] # data_id = 2\n",
        "\n",
        "dir_data_h5 = Path(r'data_h5')\n",
        "dir_data_h5.mkdir(exist_ok = True)\n",
        "url = urls_h5[data_id][1]\n",
        "download_file(url, str(dir_data_h5/\"download.zip\"))\n",
        "!unzip data_h5/download.zip -d data_h5\n",
        "os.remove(dir_data_h5/\"download.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72,
          "referenced_widgets": [
            "80762d452fa340189e276a52accf776e"
          ]
        },
        "id": "Po8l28gP5bja",
        "outputId": "935657b2-1564-4e85-9d3b-6d79bd115d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80762d452fa340189e276a52accf776e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data_h5/download.zip:   0%|          | 0/269045196 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  data_h5/download.zip\n",
            "replace data_h5/g1-with_internal_1.1_Umf_1.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 | Select Data"
      ],
      "metadata": {
        "id": "pkfa2ZvTkmVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select and load dataset\n",
        "# ------------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------------\n",
        "dataset_id = 6   # <- change this to the id of the file you want to load and process\n",
        "                 #    the dataset_id is related to the list \"available datasets\"\n",
        "# ------------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "dataset_list = os.listdir(\"data_h5\")\n",
        "dataset_list.sort()\n",
        "print('available datasets:')\n",
        "for i, dataset in enumerate(dataset_list):\n",
        "    print(\"dataset_id=\"+str(i), dataset)\n",
        "current_dataset = dataset_list[dataset_id]\n",
        "print('\\ncurrent_dataset is:')\n",
        "print(current_dataset)\n",
        "# load dataset\n",
        "dataset_path = \"data_h5/\" + current_dataset #comment\n",
        "video_array = read_from_h5(dataset_path)\n",
        "video_array = video_array.astype(float) / 255"
      ],
      "metadata": {
        "id": "m6Ryny9n5wxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 | Find suitable parameters\n",
        "This part will help you to determine suitable data processing parameters. Remember: each dataset may require different processing parameters if the camera orientation changed, the crop needs to be adjusted. If the lightning setup changed, the brightness_factor needs to change. The best working threshold for segmentation is connected to the general brightness of the image and therefore changes with the brightness_factor.\n",
        "\n",
        "### Determine Crop\n",
        "Further crop the data to the area of interest. Discuss in your group and with the tutors, which areas should be analyzed and which ones should not!"
      ],
      "metadata": {
        "id": "m5TklC72bpfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------- change parameters here -------------------------- #\n",
        "crop_left = 45\n",
        "crop_right = 50\n",
        "crop_top = 60\n",
        "crop_bot = 110\n",
        "# -------------------------- change parameters here -------------------------- #\n",
        "\n",
        "random_frame_id = random.randrange(0, video_array.shape[2])\n",
        "frame = video_array[:,:,random_frame_id]\n",
        "\n",
        "video_array_cropped = video_array[crop_top:-crop_bot, crop_left:-crop_right, :]\n",
        "frame_cropped = video_array_cropped[:,:,random_frame_id]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "axs[0].imshow(frame, cmap='gray',vmin=0, vmax=1)\n",
        "axs[0].set_title('original image with crop visualization')\n",
        "axs[0].text(30,50, current_dataset, c=\"white\", size=14, va=\"top\")\n",
        "rect = patches.Rectangle((crop_left, crop_top), frame.shape[1]-crop_left-crop_right, frame.shape[0]-crop_top-crop_bot, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
        "axs[0].add_patch(rect)\n",
        "axs[1].imshow(frame_cropped, cmap='gray',vmin=0, vmax=1)\n",
        "axs[1].set_title('resulting cropped image')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "krwgy2vabpAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine insert masking area\n",
        "\n",
        "In this section we want to mask the insert. Some part of the fluidized bed is blocked by the insert. We want to exclude this area from the analysis. The excluded area is previewed by the blue rectangle. Adjust the parameters, so that the area matches the actual insert. If you are working with with data without internal, you may switch off masking by setting `masking = False`\n",
        "\n",
        "Caution: When the crop in the previous cell is changed, these parameters have to be adjusted!"
      ],
      "metadata": {
        "id": "Z_4i0nWNbhcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------- change parameters here -------------------------- #\n",
        "masking = True\n",
        "pad_left = 0\n",
        "pad_right = 0\n",
        "pad_top = 435\n",
        "pad_bot = 0\n",
        "# -------------------------- change parameters here -------------------------- #\n",
        "\n",
        "random_frame_id = random.randrange(0, video_array.shape[2])\n",
        "frame = video_array_cropped[:,:,random_frame_id]\n",
        "\n",
        "fig, axs = plt.subplots(1, 1, figsize=(15, 10))\n",
        "axs.imshow(frame, cmap='gray',vmin=0, vmax=1)\n",
        "axs.set_title('original image with crop visualization')\n",
        "axs.text(30,50, current_dataset, c=\"white\", size=14, va=\"top\")\n",
        "rect = patches.Rectangle((pad_left, pad_top), frame.shape[1]-pad_left-pad_right, frame.shape[0]-pad_top-pad_bot, linewidth=1, edgecolor=\"b\", facecolor=\"none\")\n",
        "axs.add_patch(rect)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "FeTIw4Jqds8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determin Brightness Factor\n",
        "\n",
        "We want to adjust the global brightness, so that the full value range (0 to 1) is utilized. Make the image as bright as possible, without loosing many details by clipping. Clipping means that values exceed the maximum value 1.0 and therefore get \"clipped\" back to 1.0. In a heavily clipped / overexposed image, most of the imgage is plain white with many pixel values being exactly 1.0. Use the histogram to find a good value.\n",
        "\n",
        "If you are not familiar with histograms and how to read them, research this inforamtion."
      ],
      "metadata": {
        "id": "03hKh3X3je_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------- change parameters here -------------------------- #\n",
        "brightness_factor = 1.6\n",
        "# -------------------------- change parameters here -------------------------- #\n",
        "\n",
        "video_array_bright = video_array_cropped * brightness_factor\n",
        "video_array_bright = np.fmin(video_array_bright, 1.)\n",
        "\n",
        "random_frame_id = random.randrange(0, video_array_cropped.shape[2])\n",
        "frame = video_array_cropped[:,:,random_frame_id]\n",
        "frame_bright = video_array_bright[:,:,random_frame_id]\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 10))\n",
        "axs[0].imshow(frame, cmap='gray',vmin=0, vmax=1)\n",
        "axs[0].set_title('original image')\n",
        "axs[0].text(30,50, current_dataset, c=\"white\", size=14, va=\"top\")\n",
        "axs[1].imshow(frame_bright, cmap='gray',vmin=0, vmax=1)\n",
        "axs[1].set_title('cropped image with applied brightness_factor')\n",
        "axs[2].hist(frame_bright.reshape(-1), bins=128, range=(0,1))\n",
        "axs[2].set_title('histogram after applied brightness_factor')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "yHLpPuEhd9v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine segmentation threshold"
      ],
      "metadata": {
        "id": "MvKtbdBHjkta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot image grid with various different segmentation thresholds\n",
        "frame_index = 25\n",
        "frame = video_array_bright[:,:,frame_index]\n",
        "\n",
        "fig, axs = plt.subplots(2, 5, figsize=(15,8))\n",
        "for threshold, ax in zip(np.linspace(start=0.1,stop=0.9,num=10), axs.flatten()):\n",
        "    computed_mask = frame < threshold\n",
        "    ax.imshow(computed_mask, cmap='gray', vmin=0, vmax=1)\n",
        "    ax.set_title(\"Threshold value = \" + str(round(threshold, 2)))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "2c7RGRarjiF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------- change parameters here -------------------------- #\n",
        "threshold = 0.7\n",
        "# -------------------------- change parameters here -------------------------- #\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,10))\n",
        "axs[0].imshow(frame_bright, cmap='gray',vmin=0, vmax=1)\n",
        "axs[0].set_title(\"original image\")\n",
        "computed_mask = frame_bright < threshold\n",
        "axs[1].imshow(computed_mask, cmap='gray')\n",
        "axs[1].set_title(\"resulting mask with the threshold you chose\")"
      ],
      "metadata": {
        "id": "pkVZ49W3jshc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter summary\n",
        "print(\"These are the parameters you have selected:\")\n",
        "print(f\"{crop_left=}, {crop_right=}, {crop_top=}, {crop_bot=}\")\n",
        "print(f\"{brightness_factor=}\")\n",
        "print(f\"{threshold=}\")\n",
        "print(f\"{masking=}\")\n",
        "print(f\"{pad_left=}, {pad_right=}, {pad_top=}, {pad_bot=}\")\n",
        "print(f\"{threshold=}\")"
      ],
      "metadata": {
        "id": "m2t1m6bkuJNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4 | Segmentation\n",
        "This script is responsible for the binary mask computation. Familiarize with the filters and functions used."
      ],
      "metadata": {
        "id": "aEyOEnm8txPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from skimage import (\n",
        "    filters, measure, morphology, segmentation\n",
        ")\n",
        "from skimage.data import protein_transport\n",
        "from scipy import ndimage as ndi\n",
        "# binary mask computation\n",
        "# computed_mask1, computed_mask2 etc. are further and furhter refinement steps\n",
        "frame_index = 25\n",
        "frame = video_array_bright[:, :, frame_index]\n",
        "\n",
        "frame =  filters.gaussian(frame,sigma = 1.1)\n",
        "thresh = frame < filters.threshold_local(frame, 191, 'mean')\n",
        "fill = ndi.binary_fill_holes(thresh)\n",
        "\n",
        "# step 1: apply threshold\n",
        "computed_mask1 = thresh# fill#frame < threshold\n",
        "\n",
        "# step 2: black out the inlet area\n",
        "computed_mask2 = computed_mask1.copy()\n",
        "if masking:\n",
        "    computed_mask2[pad_top:-pad_bot, pad_left:-pad_right] = 0\n",
        "\n",
        "# step 3: remove small white areas with area <8 pixels\n",
        "computed_mask3 = morphology.area_opening(computed_mask2, area_threshold=8)\n",
        "\n",
        "# step 4: dilate (enlarge) white area with disk\n",
        "disk = morphology.disk(5)\n",
        "computed_mask4 = morphology.binary_dilation(computed_mask3, selem=disk)\n",
        "\n",
        "# step 5: remove white areas with area <400 pixels\n",
        "computed_mask5 = morphology.area_opening(computed_mask4, area_threshold=10**2)\n",
        "\n",
        "# step 6: remove connected areas that begin at the very top or the very bottom\n",
        "labels, num = measure.label(computed_mask5, return_num=True)\n",
        "computed_mask6 = computed_mask5\n",
        "testpoints = [\n",
        "    labels[0, int(video_array_bright.shape[1]*0.5)],\n",
        "    labels[-1, int(video_array_bright.shape[1]*0.25)],\n",
        "    labels[-1, int(video_array_bright.shape[1]*0.5)],\n",
        "    labels[-1, int(video_array_bright.shape[1]*0.75)],\n",
        "]\n",
        "for testpoint in testpoints:\n",
        "    if testpoint != 0:\n",
        "        computed_mask6 = np.where(labels == testpoint, 0, computed_mask6)\n",
        "\n",
        "# generate figure 2 (mask creation algorithm demonstration, just for your)\n",
        "fig, axs = plt.subplots(1, 7, figsize=(20,20))\n",
        "axs[0].imshow(frame, cmap='gray',vmin=0, vmax=1)\n",
        "axs[0].set_title(\"test\")\n",
        "axs[1].imshow(computed_mask1, cmap='gray')\n",
        "axs[0].set_title(\"computed_mask1\")\n",
        "axs[2].imshow(computed_mask2, cmap='gray')\n",
        "axs[0].set_title(\"computed_mask2\")\n",
        "axs[3].imshow(computed_mask3, cmap='gray')\n",
        "axs[0].set_title(\"computed_mask3\")\n",
        "axs[4].imshow(computed_mask4, cmap='gray')\n",
        "axs[0].set_title(\"computed_mask4\")\n",
        "axs[5].imshow(computed_mask5, cmap='gray')\n",
        "axs[0].set_title(\"computed_mask5\")\n",
        "axs[6].imshow(computed_mask6, cmap='gray')\n",
        "axs[0].set_title(\"computed_mask6\")"
      ],
      "metadata": {
        "id": "9NnsxK347DzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5 | Documentation\n",
        "\n",
        "Create a documentation for your report. If you run this cell, the figure will be exported as a jpg image. The jpg file also includes the paramters that you have set for processing earlier. Include these documentation images with the settings to your report for documentation! Careful: The images are saved to google colab, remember to download the files to your computer before they are deleted automatically."
      ],
      "metadata": {
        "id": "PbC110_3cAGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "settings_string = \"\\n\".join([\n",
        "    f\"{crop_left=}, {crop_right=}\\n{crop_top=}, {crop_bot=}\",\n",
        "    f\"{brightness_factor=}\",\n",
        "    f\"{threshold=}\",\n",
        "    f\"{masking=}\",\n",
        "    f\"{pad_left=}, {pad_right=}\\n{pad_top=}, {pad_bot=}\",\n",
        "    f\"{threshold=}\",\n",
        "])\n",
        "\n",
        "random_frame_id = random.randrange(0, video_array.shape[2])\n",
        "frame = video_array[:,:,random_frame_id]\n",
        "frame_bright = video_array_bright[:,:,random_frame_id]\n",
        "\n",
        "# generate figure 1 (settings overview for documentation. include this in your report!)\n",
        "fig, axs = plt.subplots(1, 4, figsize=(25, 12))\n",
        "axs[0].imshow(frame, cmap='gray', vmin=0, vmax=1)\n",
        "axs[0].set_title('original image')\n",
        "axs[0].text(30,50, current_dataset, c=\"white\", size=12, va=\"top\")\n",
        "axs[0].text(30,120, settings_string, c=\"white\", size=12, va=\"top\")\n",
        "axs[1].imshow(frame_bright, cmap='gray', vmin=0, vmax=1)\n",
        "axs[1].set_title('cropped image with applied brightness_factor')\n",
        "axs[2].imshow(computed_mask6, cmap='gray')\n",
        "axs[2].set_title('computed binary mask')\n",
        "axs[3].hist(frame_bright.reshape(-1), bins=128, range=(0,1))\n",
        "axs[3].set_title('brightness histogram after applied brightness_factor')\n",
        "# plt.tight_layout()\n",
        "\n",
        "# save image\n",
        "timestamp_string = datetime.now().strftime(\"%Y-%m-%d_%Hh%Mm\")\n",
        "image_filename = f\"settings_{current_dataset}_{timestamp_string}.jpg\"\n",
        "plt.savefig(image_filename, dpi=150)"
      ],
      "metadata": {
        "id": "ylF-YAZNcFL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}